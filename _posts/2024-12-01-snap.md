---
title: YouTube 핫클립 자동생성기
date: 2024-03-29
categories: [Projects, AI]
tags: [영상처리, 자동화, YouTube, 쇼츠, 클립생성, 컨텐츠제작, AI서비스, PyTorch, LangChain, Docker]
---

<div class="project-container">
  <div class="project-section info-section">
    <h2>프로젝트 소개</h2>
    <div class="project-info">
      <div class="video-container">
        <video controls>
          <source src="https://github.com/user-attachments/assets/49ba65e1-83b6-409a-8839-ebbea9bdd01b" type="video/mp4">
          <p>브라우저가 비디오를 지원하지 않습니다.</p>
        </video>
      </div>
      <p>
        크리에이터들이 긴 영상에서 인기 있을 만한 순간을 자동으로 찾고, 편집하여 쇼츠용 클립을 제작하도록 지원하는 서비스입니다.
      </p>
      <strong>Github</strong> <a href="https://github.com/in-sukim/SNAP">Link</a><br>
      <strong>개발 기간</strong> 2024.02 ~ 2024.03 (2개월)<br>
      <strong>인원</strong> 5명 (부스트캠프 AI Tech - 팀프로젝트)<br>
      <strong>역할</strong> AI 엔지니어<br>
      <strong>개발환경</strong> Naver Cloud Platform (Linux)<br>
      <strong>인</strong> Tesla V100 32GB * 6<br>
      <strong>기술 스택</strong>
      <div class="tech-badges">
        <div class="badge-group">
          <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
          <img src="https://img.shields.io/badge/langchain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white" alt="langchain">
          <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker">
          <img src="https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white" alt="MySQL">
          <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI">
        </div>
      </div>
    </div>
  </div>

  <div class="project-section main-features">
    <h2>주요 구현 기능</h2>
    <div class="features-tabs">
      <div class="tab-buttons">
        <button class="tab-button active" data-tab="feature1"><strong>sLLM Text Summarization</strong></button>
        <button class="tab-button" data-tab="feature2"><strong>멀티모달 모델 서빙</strong></button>
      </div>
      <div class="tab-content active" id="feature1">
        <div class="feature-item">
          <h3>1. sLLM Text Summarization</h3>
          <div class="section-content">
            <div class="tech-badges">
              <div class="badge-group">
                <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white" alt="PyTorch">
                <img src="https://img.shields.io/badge/langchain-1C3C3C?style=for-the-badge&logo=langchain&logoColor=white" alt="langchain">
              </div>
            </div>
            <h3>주요 기능</h3>
            <ul class="feature-list">
              <li><strong>Extractive-Abstractive 요약</strong>
                <ul>
                  <li>Chunk 단위 3개 주요문장 추출(Extractive) 요약</li>
                  <li>Map 결과 종합 5개 주요정보 추상(Abstractive) 요약</li>
                  <li>선행연구 결과 사실적 수준 평가지표(FactCC, QuestEval) 높은 성능</li>
                </ul>
              </li>
              <li><strong>멀티모달 결합 요약</strong>
                <ul>
                  <li>사실적 추출 성능 향상을 위한 Vision 모달리티 결합</li>
                  <li>핫클립 장면 5개 요약, Moment Retrieval(Vision)과 결합</li>
                </ul>
              </li>
            </ul>
            <h3>성과</h3>
            <ul class="feature-list">
              <li>요약 속도 시간 약 50% 개선</li>
              <li>자체 구축 평가데이터셋 Hit Rate 18.52% 달성</li>
            </ul>
            <h3>Technical Challenges & Solutions</h3>
            <ul class="feature-list">
              <li>
                <strong>긴 영상 처리의 Context Window 한계</strong><br><br>
                20~30분 길이의 영상에서 7분~1분 길이의 영상 스크립트를 요약하는 과정에서, LLM의 Context Window 제한으로 인해 전체 내용을 한 번에 처리하지 못하는 문제가 발생했습니다.<br><br>
                이를 해결하기 위해 Mistral 7B 모델을 4-bit Quantization하여 메모리 사용량을 줄이고, Map-Reduce 방식의 Extractive-Abstractive 요약 방법을 적용했습니다. 전체 스크립트를 Chunk 단위로 나누어 각각 3개의 주요 문장을 추출(Map)하고, 이를 다시 결합하여 5개의 주요 정보로 추상화(Reduce)하는 방식을 채택했습니다.<br><br>
                그 결과 8192 토큰의 Context Window를 효율적으로 활용할 수 있었고, 요약 처리 시간을 약 50% 단축할 수 있었습니다.
              </li>
              <br>
              <li>
                <strong>멀티모달 결합을 통한 성능 개선</strong><br><br>
                텍스트 정보를 이용한 요약에서는 영상의 시각적 정보를 활용하지 못해 중요한 장면이나 맥락을 놓치는 문제가 있었습니다. 특히 핫클립으로 활용될 만한 시각적으로 흥미로운 순간들을 포착하지 못하는 한계가 있었습니다.<br><br>
                이를 해결하기 위해 Vision Modality와 결합 가능한 Extractive-Abstractive 프롬프트를 설계했습니다. 시각적으로 중요한 5개 장면을 Moment Retrieval을 통해 추출하고, 이를 텍스트 요약 결과와 결합하여 최종 요약을 생성했습니다.<br><br>
                그 결과 Text Only 대비 카테고리별 평균 Hit Rate가 약 3.1% 개선되었으며, 시각적으로도 의미 있는 핫클립을 생성할 수 있게 되었습니다.
              </li>
            </ul>
          </div>
        </div>
      </div>
      <div class="tab-content" id="feature2">
        <div class="feature-item">
          <h3>2. 멀티모달 모델 서빙</h3>
          <div class="section-content">
            <div class="tech-badges">
              <div class="badge-group">
                <img src="https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white" alt="Docker">
                <img src="https://img.shields.io/badge/MySQL-4479A1?style=for-the-badge&logo=mysql&logoColor=white" alt="MySQL">
                <img src="https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="OpenAI">
              </div>
            </div>
            <h3>주요 기능</h3>
            <ul class="feature-list">
              <li><strong>모델 서빙 최적화</strong>
                <ul>
                  <li>Audio, Text, Vision 각 모달리티별 모델의 개별 서빙</li>
                  <li>파이프라인 복잡도 증가 문제 해결</li>
                  <li>모달리티별 패키지 의존성 문제 해결</li>
                </ul>
              </li>
              <li><strong>인프라 구축</strong>
                <ul>
                  <li>Multi-stage build를 통한 이미지 크기 최적화</li>
                  <li>Docker Compose 기반 통합 구현</li>
                </ul>
              </li>
            </ul>
            <h3>성과</h3>
            <ul class="feature-list">
              <li>전체 파이프라인 처리 시간 단축</li>
              <li>안정적인 서비스 운영 환경 구축</li>
            </ul>
            <h3>Technical Challenges & Solutions</h3>
            <ul class="feature-list">
              <li>
                <strong>멀티모달 모델 서빙 최적화</strong><br><br>
                Audio, Text, Vision 각 모달리티별 모델을 통합 서빙하는 과정에서 파이프라인 복잡도가 증가하고, 특히 PyTorch와 CUDA 버전 등 패키지 의존성 충돌 문제로 인해 팀원들의 개발 환경 구성과 협업에 어려움이 발생했습니다.<br><br>
                이러한 문제를 해결하기 위해 제가 주도적으로 Docker 기반의 마이크로서비스 아키텍처를 설계하고 도입했습니다. 각 모달리티별 모델을 개별 컨테이너로 분리하고, 필요한 최소한의 패키지만을 포함하는 경량화된 도커 이미지를 구성했습니다. 또한 Multi-stage build를 활용하여 개발 환경과 운영 환경의 이미지를 분리하고, Docker Compose를 통해 서비스 간 통신과 리소스 관리를 효율화했습니다.<br><br>
                그 결과 팀원들이 동일한 개발 환경에서 원활하게 협업할 수 있게 되었고, 각 모달리티별 서비스의 안정성을 확보하며 배포가 용이한 환경을 구축할 수 있었습니다.
              </li>
            </ul>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<div class="architecture-diagram">
  <img src="assets/img/snap/system.png" alt="시스템 아키텍처">
  <img src="assets/img/snap/infra.png" alt="인프라 구조도">
</div>

<script src="/assets/js/projects.js"></script>

